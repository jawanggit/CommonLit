{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "35c29735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from string import punctuation\n",
    "import re\n",
    "import lightgbm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "62eea67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b3112115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = train[train.excerpt.str.contains(\"U. \", regex=True)].excerpt\n",
    "# a.values\n",
    "# # df_dialogue = pd.DataFrame(list(c_df.excerpt.str.contains(\"\\\".*\\\"\",regex = True).astype(int)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "028a5246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_char(text):\n",
    "    num = random.randint(15,35)\n",
    "    num2 = random.randint(0,1)\n",
    "    \n",
    "    if num2 == 0:\n",
    "        return text+text[0:num]\n",
    "    else:\n",
    "        return text[:-num]\n",
    "# ------------------------------------\n",
    "def target_jitter(df):\n",
    "    lst = list(zip(df.target, df.standard_error))\n",
    "    final_lst = []\n",
    "    for val in lst:\n",
    "        num = random.randint(0,1)\n",
    "        error = random.uniform(0, val[1])\n",
    "        if num ==0:\n",
    "            final_lst.append(val[0]+error)\n",
    "        else:\n",
    "            final_lst.append(val[0]-error)\n",
    "    df['target'] = final_lst\n",
    "    return df\n",
    "    \n",
    "    \n",
    "# ------------------------------------\n",
    "def word_length_counts(text):\n",
    "    '''\n",
    "        Return: \n",
    "            Dictionry of words length counts \n",
    "    '''\n",
    "    \n",
    "    d = {\"1_letter\": 0, \n",
    "         \"2_letter\": 0, \n",
    "         \"3_letter\": 0, \n",
    "         \"4_letter\": 0, \n",
    "         \"5_letter\": 0, \n",
    "         \"6_letter\": 0, \n",
    "         \"7_letter\": 0, \n",
    "         \"8_letter\": 0, \n",
    "         \"9_letter\": 0, \n",
    "         \"10_letter\": 0, \n",
    "         \"11_letter\": 0, \n",
    "         \"12_letter\": 0\n",
    "    }\n",
    "\n",
    "    text.replace('\\n', '')\n",
    "    text = text.lower()\n",
    "    n_text = ''\n",
    "    for c in text: \n",
    "        if c not in punctuation:\n",
    "            n_text += c\n",
    "        else: n_text += ' '\n",
    "\n",
    "    text = n_text\n",
    "    for word in text.split(' '): \n",
    "        wl = len(word)\n",
    "        if wl > 0:\n",
    "            if len(word) >= 12: key = f\"12_letter\"\n",
    "            else:  key = f\"{len(word)}_letter\"\n",
    "\n",
    "            d[key] += 1; \n",
    "    return d\n",
    "# ------------------------------------\n",
    "def source_info(text):\n",
    "    '''\n",
    "        Return: \n",
    "            Dictionary of source wiki, article, book, details, story or stories, kid, edu, simple\n",
    "    '''\n",
    "    d = dict()\n",
    "    source_type = ['wiki', 'article', 'book', 'details', 'kid', 'edu', 'simple', 'story', 'stories']\n",
    "    \n",
    "    for t in source_type:\n",
    "        if t != 'stories': \n",
    "            d[t] = 0\n",
    "            \n",
    "        if t in text:\n",
    "            if t == 'stories': \n",
    "                d['story'] = 1;\n",
    "            else: d[t] = 1\n",
    "    return d\n",
    "# ------------------------------------\n",
    "def document_info(text):\n",
    "    '''\n",
    "        Return:\n",
    "            Dictionary of document lenght, word count, sentence count, average word lenght\n",
    "    '''\n",
    "    text_lenght = len(text)\n",
    "    text = text.replace('\\n', ' ')\n",
    "    text_word_count = len(text.split(' '))\n",
    "    text_sentence_count = len(re.split('\\.|!|\\?',text)) # modified by James\n",
    "    text = re.split('\\.|!|\\?',text)\n",
    "    text_avg_word_length = round(sum([len(t) for t in text]) / text_word_count, 2)\n",
    "\n",
    "    document_info = {\n",
    "        'doc_len': text_lenght,\n",
    "        'word_count': text_word_count,\n",
    "        'sent_count': text_sentence_count,\n",
    "        'avg_word_len': text_avg_word_length\n",
    "    }\n",
    "\n",
    "    return document_info\n",
    "#----------------------------------------\n",
    "def words_per_sentence(text):\n",
    "   \n",
    "    total = []\n",
    "    text = text.replace('Mrs.',\"Mrs\")\n",
    "    text = text.replace('Mr.',\"Mr\")\n",
    "    text = text.replace('Dr.',\"Dr\")\n",
    "    text = text.replace('Capt.',\"Capt\")\n",
    "    text = text.replace('U.S.',\"U S\")\n",
    "    text = text.replace('U. S.',\"U S\")\n",
    "    \n",
    "    sentences = re.split('\\. |! |\\? ',text)\n",
    "    for sentence in sentences: #iterate over list of sentences\n",
    "        if sentence != '':\n",
    "            word_list = sentence.split(' ') #split a sentence into list of words\n",
    "            while(\"\" in word_list):\n",
    "                word_list.remove(\"\")\n",
    "            while('\"' in word_list):\n",
    "                word_list.remove('\"')\n",
    "            total.append(len(word_list)) #total number of words in a sentence add to list\n",
    "    return np.mean(total)\n",
    "    \n",
    "# ------------------------------------\n",
    "def character_counts(text):\n",
    "    '''\n",
    "        Return:\n",
    "            Dictionary of counts of all characters in text\n",
    "    '''\n",
    "    char_dict = dict()\n",
    "    text = text.lower()\n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    for char in text:\n",
    "        if char not in char_dict:\n",
    "            char_dict[char] = 0\n",
    "        \n",
    "        char_dict[char] += 1     \n",
    "        \n",
    "    return char_dict\n",
    "\n",
    "# ------------------------------------\n",
    "def phonemes_counts(text):\n",
    "    '''\n",
    "        Return: \n",
    "            Dictionay of all phonemic in text\n",
    "    '''\n",
    "    phonemes = ['ck', 'cc', 'di', 'nn', 'dd', 'ai', 'ss', 'mn', 'bb', \n",
    "                'sci', 'ze', 'qu', 'se', 'sc', 'ci', 'ps', 'si', 'tch', \n",
    "                'ngue', 'st', 'gu', 'th', 'pn', 've', 'te', 'zz', 'au', \n",
    "                'lm', 'lf', 'ge', 'wh', 'tu', 'wr', 'ph', 'sh', 'mm', 'gh', \n",
    "                'dge', 'ft', 'tt', 'ed', 'ng', 'lk', 'ti', 'gue', 'rr', 'ch', \n",
    "                'll', 'gn', 'ff', 'gg', 'pp', 'rh', 'ce', 'mb', 'kn', \n",
    "                'eer', 'ere', 'uy', 'ho', 'ear', 'ei', 'ar', 'ai', \n",
    "                'oor', 'ure', 'eigh', 'ey', 'is', 'ae', 'ow', 'or', 'ew', \n",
    "                'ore', 'ur', 'uoy', 'air', 'au', 'ough', 'yr', \n",
    "                'ea', 'ayer', 'augh', 'aw', 'eau', 'aigh', 'igh', 'oy', \n",
    "                'oo', 'ue', 'are', 'ee', 'oa', 'et', 'y', 'er', 'eir', \n",
    "                'oew', 'oar', 'ie', 'eo', 'ui', 'ier', 'ou', 'ir', 'oi', \n",
    "                'ay', 'ye', 'oe', 'our']\n",
    "    temp_dict = dict()\n",
    "    \n",
    "    # lower text \n",
    "    text = text.lower()\n",
    "    \n",
    "    for p in phonemes:\n",
    "        temp_dict[p] = text.count(p)\n",
    "    \n",
    "    return temp_dict\n",
    "\n",
    "#-----------------------\n",
    "def add_data(df,float1,float2):\n",
    "    group = df.loc[(df.target<float1) | (df.target>float2)]\n",
    "    group = group.copy()\n",
    "    group['mod'] =  group.excerpt.apply(lambda x: remove_char(x))\n",
    "    group.drop(columns =['excerpt'],axis = 1,inplace = True)\n",
    "    group = group.rename(columns = {\"mod\":\"excerpt\"})\n",
    "    target_jitter(group)\n",
    "    mod_train = pd.concat([df,group],sort = 'False')\n",
    "    train = mod_train\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c42766de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = add_data(train,-2,1)\n",
    "train = add_data(train,-5,1)\n",
    "train = add_data(train,-5,1)\n",
    "train = add_data(train,-5,1)\n",
    "train = add_data(train,-5,1.25)\n",
    "train = add_data(train,-5,1.25)\n",
    "train = add_data(train,-5,1.25)\n",
    "train = add_data(train,-2,6)\n",
    "\n",
    "\n",
    "train.target.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "bbbaeb17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-223-a4d1b9e30855>:3: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  c_df = pd.concat([train, test], axis = 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6863, 6)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#combine train and test set for pre-processing\n",
    "\n",
    "c_df = pd.concat([train, test], axis = 0)\n",
    "c_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "50adc5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_documents =  c_df.excerpt.apply(lambda x: document_info(x))\n",
    "series_phonemes = c_df.excerpt.apply(lambda x: phonemes_counts(x))\n",
    "series_characters =  c_df.excerpt.apply(lambda x: character_counts(x))\n",
    "series_word_length = c_df.excerpt.apply(lambda x: word_lenth_counts(x))\n",
    "series_word_per_sent = c_df.excerpt.apply(lambda x: words_per_sentence(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d42e67b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_documents = pd.DataFrame(list(series_documents))\n",
    "df_phonemes = pd.DataFrame(list(series_phonemes))\n",
    "df_chracters = pd.DataFrame(list(series_characters))\n",
    "df_word_length = pd.DataFrame(list(series_word_length))\n",
    "df_word_per_sent = pd.DataFrame(list(series_word_per_sent))\n",
    "df_word_per_sent.rename(columns={0:'wps'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0095f6d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9844"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_word_lenght)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e00a9628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make na 0\n",
    "df_chracters.fillna(0, inplace = True)\n",
    "#df_chracters_test.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# Make all ints (change NaN to 0)\n",
    "for col in df_chracters.columns:\n",
    "    df_chracters[col] = df_chracters[col].astype(int, copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "785aa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dialogue = pd.DataFrame(list(c_df.excerpt.str.contains(\"\\\".*\\\"\",regex = True).astype(int)))\n",
    "df_dialogue.rename(columns = {0:'dialogue'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "7431aba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = pd.concat([df_documents, df_phonemes, df_word_length,df_word_per_sent,df_dialogue], axis = 1)\n",
    "#df_X_test = pd.concat([df_documents_test, df_phonemes_test, df_word_lenght_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "6fbd0f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6863"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "86870ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df_X.T.drop_duplicates().T\n",
    "# df_X_test = df_X_test.T.drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "96a7fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test = df_X.iloc[-len(test):]\n",
    "df_X = df_X.iloc[:-len(test)]\n",
    "df_y = c_df['target'][:-len(test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "fc5f6447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "print(scaler.fit(df_X))\n",
    "# print(scaler.data_max_)\n",
    "x_train = scaler.transform(df_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "01cbbba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>ck</th>\n",
       "      <th>cc</th>\n",
       "      <th>di</th>\n",
       "      <th>nn</th>\n",
       "      <th>dd</th>\n",
       "      <th>ai</th>\n",
       "      <th>...</th>\n",
       "      <th>5_letter</th>\n",
       "      <th>6_letter</th>\n",
       "      <th>7_letter</th>\n",
       "      <th>8_letter</th>\n",
       "      <th>9_letter</th>\n",
       "      <th>10_letter</th>\n",
       "      <th>11_letter</th>\n",
       "      <th>12_letter</th>\n",
       "      <th>wps</th>\n",
       "      <th>dialogue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>992.0</td>\n",
       "      <td>179.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>937.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>908.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>909.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.750000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>723.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.400000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>1064.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.333333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6852</th>\n",
       "      <td>1390.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.87</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>24.875000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>1041.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>28.800000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>1193.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>1112.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6856 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      doc_len  word_count  sent_count  avg_word_len   ck   cc   di   nn   dd  \\\n",
       "0       992.0       179.0        12.0          5.48  1.0  0.0  1.0  0.0  0.0   \n",
       "1       937.0       169.0        18.0          5.44  0.0  0.0  1.0  1.0  1.0   \n",
       "2       908.0       166.0        13.0          5.40  3.0  1.0  1.0  1.0  1.0   \n",
       "3       909.0       164.0         6.0          5.51  0.0  0.0  0.0  0.0  0.0   \n",
       "4       723.0       147.0         6.0          4.88  0.0  0.0  0.0  0.0  7.0   \n",
       "...       ...         ...         ...           ...  ...  ...  ...  ...  ...   \n",
       "6851   1064.0       158.0         6.0          6.70  0.0  0.0  1.0  1.0  0.0   \n",
       "6852   1390.0       201.0        11.0          6.87  1.0  1.0  6.0  0.0  0.0   \n",
       "6853   1041.0       145.0         6.0          7.14  0.0  0.0  4.0  0.0  0.0   \n",
       "6854   1193.0       183.0         9.0          6.48  0.0  0.0  8.0  2.0  0.0   \n",
       "6855   1112.0       170.0        12.0          6.48  0.0  0.0  9.0  0.0  1.0   \n",
       "\n",
       "       ai  ...  5_letter  6_letter  7_letter  8_letter  9_letter  10_letter  \\\n",
       "0     1.0  ...      21.0      10.0       9.0      10.0       8.0        3.0   \n",
       "1     3.0  ...      17.0      15.0      12.0       5.0       2.0        5.0   \n",
       "2     4.0  ...      24.0       7.0      11.0       9.0       3.0        2.0   \n",
       "3     3.0  ...      21.0      20.0      15.0       4.0       1.0        1.0   \n",
       "4     4.0  ...      28.0      14.0       0.0       2.0       0.0        0.0   \n",
       "...   ...  ...       ...       ...       ...       ...       ...        ...   \n",
       "6851  4.0  ...      18.0      15.0      12.0      13.0       4.0        3.0   \n",
       "6852  0.0  ...      19.0      19.0      23.0      13.0      10.0       18.0   \n",
       "6853  1.0  ...      11.0      10.0      14.0      13.0       6.0       11.0   \n",
       "6854  0.0  ...      21.0      15.0      16.0      21.0      10.0        4.0   \n",
       "6855  1.0  ...      16.0      12.0      15.0      17.0       8.0        4.0   \n",
       "\n",
       "      11_letter  12_letter        wps  dialogue  \n",
       "0           0.0        0.0  29.000000       0.0  \n",
       "1           2.0        0.0  20.500000       1.0  \n",
       "2           0.0        0.0  27.000000       1.0  \n",
       "3           0.0        1.0  40.750000       0.0  \n",
       "4           0.0        0.0  29.400000       0.0  \n",
       "...         ...        ...        ...       ...  \n",
       "6851        3.0       15.0  26.333333       1.0  \n",
       "6852        6.0        7.0  24.875000       0.0  \n",
       "6853        4.0       11.0  28.800000       0.0  \n",
       "6854        3.0        7.0  26.000000       0.0  \n",
       "6855       10.0        5.0  17.000000       0.0  \n",
       "\n",
       "[6856 rows x 126 columns]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5f9bff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33995609043478475\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-1.04486871, -0.6050779 , -0.20503788, -0.2595094 , -0.23601656])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = LGBMRegressor(reg_alpha = .7,n_estimators = 200, max_depth = 90)\n",
    "model.fit(x_train, df_y)\n",
    "predictions = model.predict(x_train)\n",
    "print(mean_squared_error(df_y, predictions, squared=False))\n",
    "cv_results = cross_validate(model, x_train, df_y, cv=5, scoring = 'neg_mean_squared_error')\n",
    "cv_results['test_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e1db99e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LGBMRegressor(reg_alpha = .7,n_estimators = 200, max_depth = 90)\n",
    "\n",
    "# # Number of trees in random forest\n",
    "# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# # Number of features to consider at every split\n",
    "# reg_alpha = [.1, .3, .5, .7]\n",
    "# # Maximum number of levels in tree\n",
    "# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "# max_depth.append(None)\n",
    "# # Minimum number of samples required to split a node\n",
    "# min_samples_split = [2, 5, 10]\n",
    "# # Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# # Method of selecting samples for training each tree\n",
    "# bootstrap = [True, False]\n",
    "# # Create the random grid\n",
    "# random_grid = {'n_estimators': n_estimators,\n",
    "#                'reg_alpha': reg_alpha,\n",
    "#                'max_depth': max_depth}\n",
    "# #                'min_samples_split': min_samples_split,\n",
    "# #                'min_samples_leaf': min_samples_leaf,\n",
    "# #                'bootstrap': bootstrap}\n",
    "\n",
    "# lgbm = RandomizedSearchCV(estimator = model, param_distributions = random_grid, n_iter = 100, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "# lgbm.fit(x_train, df_y.values)\n",
    "\n",
    "# lgbm.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8a85e1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b34cb4db",
   "metadata": {},
   "source": [
    "0.18521327149622654\n",
    "\n",
    "array([-0.65220468, -0.91898488, -0.6521347 , -0.65389525, -0.51162564])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7ffed",
   "metadata": {},
   "source": [
    "\n",
    "rmse on all of train set: 0.34223721516434713\n",
    "\n",
    "cv scores on train set: array([-0.64555456, -0.89791719, -0.66510866, -0.64580063, -0.50631569])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6670971b",
   "metadata": {},
   "source": [
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "fac45a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_test\n",
    "x_test = scaler.transform(df_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "2924eb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.45908239,  0.5548321 , -0.80371828, -1.85077291, -1.18285796,\n",
       "       -1.75362655, -0.74405175])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "ff82cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7c871fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['id'] = test.id.values\n",
    "submission = submission.rename(columns = {0:'target'})\n",
    "submission = submission[['id','target']]\n",
    "submission.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea82b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#submission.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284748e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#best guess ranking [2,1,3,6,5,4,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8ccec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a58dcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
